bf16: true
conversation_field: conversations
dataloader_num_workers: 2
dataset:
- fashion_multitask_dataset/conversations/train.jsonl
early_stopping_min_delta: 0.001
early_stopping_patience: 0
encoders:
  image:
    freeze: true
    model: openai/clip-vit-large-patch14
    tokenizer_type: discrete
eval_steps: 0
evaluation_strategy: 'no'
freeze_llm: false
freeze_vision_encoder: true
generate_eval_examples: false
gradient_accumulation_steps: 8
gradient_checkpointing: true
learning_rate: 2e-5
load_best_model_at_end: false
log_file: logs/training.log
logging_steps: 10
max_new_tokens: 256
max_seq_length: 4096
modalities:
  input:
  - image
  - text
  output:
  - text
model_name_or_path: Qwen/Qwen2.5-7B-Instruct
num_train_epochs: 3
output_dir: ./output/fashion_multitask_model
per_device_train_batch_size: 2
projection:
  dropout: 0.1
  hidden_size: 1024
  num_layers: 2
  type: mlp
remove_unused_columns: false
report_to: wandb
run_name: fashion_multitask_training
save_steps: 1000
save_total_limit: 5
seed: 42
special_tokens:
  image_end: </img>
  image_start: <img>
task_weights:
  next_purchase_recommendation: 1.2
  personalized_recommendation: 1.1
  product_analysis: 1.0
  product_comparison: 1.0
  review_generation: 0.8
train_projection_only: false
warmup_steps: 100
